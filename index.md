---
layout: home
title: Home
nav_order: 1
nav_exclude: false
permalink: /
seo:
  type: Course
  name: Home
---

# Deep Learning
{: .mb-2 .text-green-000}

Department of Mathematics, Sharif University. Fall 2023
{: .fs-6 .fw-300 }

![](https://ehsanmousavi1.github.io/NeuralNetwork/assets/images/site-banner.png)

This course offers an introductory exploration of deep learning, utilizing mathematical tools as its foundation. In the first half of the course, we revisit the core methods that underpin deep learning. Later on, we will cover a number of recent theoretical advances that aim to shed light on the mathematical foundations of deep learning.

#Prerequisites
The following skills will be useful for success in this course:

* **Machine Learning:** Some familiarity with machine learning will be helpful but not required; we will review important concepts that are needed for this course.

* **Programming:** You should be comfortable programming in Python. You should be familiar with algorithms and data structures. Familiarity with numpy or similar frameworks for numeric programming will be helpful but is not strictly required.

* **Probability and Linear Algebra:** You should have been exposed to probability distributions, random variables, expectations, etc.


## Course Work
Grading will be based:
* Assignments (TBA)
* Final Exam (TBA)
* Paper Presentation (TBA):


## Prerequisites
An essential component of this course involves delving deep into several papers related to specific research topics. This task is to be completed in pairs. While the choice of paper is based on your interests, it must relate to the theoretical foundations of deep learning. You are encouraged to consult with instructors and TAs when selecting your paper.

* **Proposal Submission**: By the 1st of Azar, 1402, you are required to submit a 1-page proposal outlining your chosen research topic.

* **Presentation**: During the final two weeks of the course, you will deliver a 20-minute presentation to succinctly summarize the research paper.

* **Paper Review**: You are expected to submit a concise review of the paper. This review should provide an overview of the paper, its motivation, and the important theoretical results of the work. Additionally, critically evaluate its strengths and weaknesses. Furthermore, you are encouraged (although it is optional) to further explore the results or implement the ideas and compare them with other findings.

<!--
## Lectures
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;margin:0px auto;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-mz35{border-color:#7a7fe5;text-align:center;}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-mz35"><span style="font-weight:bold">Week</span></th>
    <th class="tg-mz35" colspan="2"><span style="font-weight:bold">Topic</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-mz35" rowspan="5"><span style="font-weight:bold;font-style:italic">1 - 4</span></td>
    <td class="tg-mz35" rowspan="5">Introduction to Neural Networks</td>
    <td class="tg-mz35">History</td>
  </tr>
  <tr>
    <td class="tg-mz35">Perceptron</td>
  </tr>
  <tr>
    <td class="tg-mz35">MLP </td>
  </tr>
  <tr>
    <td class="tg-mz35">Backpropagation</td>
  </tr>
  <tr>
    <td class="tg-mz35" rowspan="5"><span style="font-weight:bold;font-style:italic">5 - 7</span></td>
    <td class="tg-mz35" rowspan="5">Enhancing Neural Networks</td>
    <td class="tg-mz35">Optimization</td>
  </tr>
  <tr>
    <td class="tg-mz35">Weight Initialization</td>
  </tr>
  <tr>
    <td class="tg-mz35">Activation Functions</td>
  </tr>
  <tr>
    <td class="tg-mz35">Learning Rate Scheduling</td>
  </tr>
  <tr>
    <td class="tg-mz35">Regularization</td>
  </tr>
  <tr>
    <td class="tg-mz35" rowspan="4"><span style="font-weight:bold;font-style:italic">8 - 11</span></td>
    <td class="tg-mz35" rowspan="4">Convolutional Neural Networks</td>
    <td class="tg-mz35">Convolution</td>
  </tr>
  <tr>
    <td class="tg-mz35">Basic Concepts</td>
  </tr>
  <tr>
    <td class="tg-mz35">Popular Architectures</td>
  </tr>
  <tr>
    <td class="tg-mz35">Applications</td>
  </tr>
  <tr>
    <td class="tg-mz35" rowspan="4"><span style="font-weight:bold;font-style:italic">12 - 14</span></td>
    <td class="tg-mz35" rowspan="4">Recurrent Neural Networks</td>
    <td class="tg-mz35">Sequential Modeling</td>
  </tr>
  <tr>
    <td class="tg-mz35">Vanilla RNN</td>
  </tr>
  <tr>
    <td class="tg-mz35">BTT</td>
  </tr>
  <tr>
    <td class="tg-mz35">LSTM &amp; GRU</td>
  </tr>
  <tr>
    <td class="tg-mz35" rowspan="4"><span style="font-weight:bold;font-style:italic">15 - 16</span></td>
    <td class="tg-mz35" rowspan="4">Advanced Topics</td>
    <td class="tg-mz35">Autoencoders</td>
  </tr>


  <tr>
    <td class="tg-mz35">Deep Reinforcement Learning</td>
  </tr>
</tbody>
</table>
-->
